(window.webpackJsonp=window.webpackJsonp||[]).push([[36],{124:function(e,t,n){"use strict";n.d(t,"a",(function(){return m})),n.d(t,"b",(function(){return d}));var a=n(0),r=n.n(a);function o(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function i(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function c(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?i(Object(n),!0).forEach((function(t){o(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):i(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function p(e,t){if(null==e)return{};var n,a,r=function(e,t){if(null==e)return{};var n,a,r={},o=Object.keys(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var s=r.a.createContext({}),l=function(e){var t=r.a.useContext(s),n=t;return e&&(n="function"==typeof e?e(t):c(c({},t),e)),n},m=function(e){var t=l(e.components);return r.a.createElement(s.Provider,{value:t},e.children)},u={inlineCode:"code",wrapper:function(e){var t=e.children;return r.a.createElement(r.a.Fragment,{},t)}},b=r.a.forwardRef((function(e,t){var n=e.components,a=e.mdxType,o=e.originalType,i=e.parentName,s=p(e,["components","mdxType","originalType","parentName"]),m=l(n),b=a,d=m["".concat(i,".").concat(b)]||m[b]||u[b]||o;return n?r.a.createElement(d,c(c({ref:t},s),{},{components:n})):r.a.createElement(d,c({ref:t},s))}));function d(e,t){var n=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var o=n.length,i=new Array(o);i[0]=b;var c={};for(var p in t)hasOwnProperty.call(t,p)&&(c[p]=t[p]);c.originalType=e,c.mdxType="string"==typeof e?e:a,i[1]=c;for(var s=2;s<o;s++)i[s]=n[s];return r.a.createElement.apply(null,i)}return r.a.createElement.apply(null,n)}b.displayName="MDXCreateElement"},246:function(e,t,n){"use strict";n.r(t),t.default=n.p+"assets/images/hyperparamtuning-170923-15e15e092f85a322bb207f399dbb63e2.png"},247:function(e,t,n){"use strict";n.r(t),t.default=n.p+"assets/images/hyperparamtuning-171041-69354b04605af8ea2deea221f34ef1d1.png"},248:function(e,t,n){"use strict";n.r(t),t.default=n.p+"assets/images/hyperparamtuning-171133-5f37f0276ee0ff9e7be663fbdaa7b195.png"},249:function(e,t,n){"use strict";n.r(t),t.default=n.p+"assets/images/hyperparamtuning-173059-7bf96693d2d1f4f366b99907e0936819.png"},96:function(e,t,n){"use strict";n.r(t),n.d(t,"frontMatter",(function(){return o})),n.d(t,"metadata",(function(){return i})),n.d(t,"rightToc",(function(){return c})),n.d(t,"default",(function(){return s}));var a=n(2),r=(n(0),n(124));const o={title:"Hyperparameter tuning",sidebar_label:"Hyperparameter tuning",description:"Onepanel - Hyperparameter tuning"},i={unversionedId:"reference/workflows/hyperparameter-tuning",id:"reference/workflows/hyperparameter-tuning",isDocsHomePage:!1,title:"Hyperparameter tuning",description:"Onepanel - Hyperparameter tuning",source:"@site/docs/reference/workflows/hyperparameter-tuning.md",slug:"/reference/workflows/hyperparameter-tuning",permalink:"/docs/reference/workflows/hyperparameter-tuning",editUrl:"https://github.com/onepanelio/core-docs/tree/master/docs/reference/workflows/hyperparameter-tuning.md",version:"current",sidebar_label:"Hyperparameter tuning",sidebar:"reference",previous:{title:"Accessing TensorBoard",permalink:"/docs/reference/workflows/tensorboard"},next:{title:"Troubleshooting Workflows",permalink:"/docs/reference/workflows/troubleshooting"}},c=[{value:"Setting up your Workflow Template",id:"setting-up-your-workflow-template",children:[]},{value:"Understanding the configurations",id:"understanding-the-configurations",children:[]},{value:"Executing your Workflow",id:"executing-your-workflow",children:[]},{value:"Persisting metrics and saving best model and parameters",id:"persisting-metrics-and-saving-best-model-and-parameters",children:[]}],p={rightToc:c};function s({components:e,...t}){return Object(r.b)("wrapper",Object(a.a)({},p,t,{components:e,mdxType:"MDXLayout"}),Object(r.b)("p",null,"Onepanel supports hyperparameter tuning for your TensorFlow and PyTorch models by fully integrating with ",Object(r.b)("a",Object(a.a)({parentName:"p"},{href:"https://github.com/microsoft/nni"}),"NNI")," and its ",Object(r.b)("a",Object(a.a)({parentName:"p"},{href:"https://nni.readthedocs.io/en/stable/Tuner/BuiltinTuner.html"}),"built-in tuners"),"."),Object(r.b)("p",null,"To understand how to add hyperparameter tuning into Onepanel Workflows, we'll walk through this ",Object(r.b)("a",Object(a.a)({parentName:"p"},{href:"https://github.com/onepanelio/templates/tree/master/workflows/hyperparameter-tuning/mnist"}),"simple MNIST example"),". Note that this example is also available when you deploy Onepanel under ",Object(r.b)("strong",{parentName:"p"},"Workflows")," > ",Object(r.b)("strong",{parentName:"p"},"Workflow Templates")," > ",Object(r.b)("strong",{parentName:"p"},"Hyperparameter Tuning Example"),", so you can ",Object(r.b)("strong",{parentName:"p"},"Clone")," it and make minor changes to make it work with your own model architecture and training code."),Object(r.b)("p",null,"There are 4 parts to configuring hyperparameter tuning into your Workflows:"),Object(r.b)("ol",null,Object(r.b)("li",{parentName:"ol"},"Model training code - Make minor updates to grab hyperparameters from NNI and report accuracies back to NNI."),Object(r.b)("li",{parentName:"ol"},"Workflow Template - Minor changes to the clone of ",Object(r.b)("strong",{parentName:"li"},"Hyperparameter Tuning Example")," that describes training pipeline with hyperparameter tuning."),Object(r.b)("li",{parentName:"ol"},"Search space configuration (",Object(r.b)("inlineCode",{parentName:"li"},"search_space.json"),") - The search space for hyperparameters and their corresponding ranges"),Object(r.b)("li",{parentName:"ol"},"Tuner configuration (",Object(r.b)("inlineCode",{parentName:"li"},"config.yaml"),")- This is where you indicate the type of tuner (e.g. TPE), path to your model training code, whether to use GPUs, etc.")),Object(r.b)("h2",{id:"setting-up-your-workflow-template"},"Setting up your Workflow Template"),Object(r.b)("ol",null,Object(r.b)("li",{parentName:"ol"},Object(r.b)("p",{parentName:"li"},"First, make changes to your training code to grab the parameters from NNI and report results back to NNI. Highlighted below are all the changes we had to make to ",Object(r.b)("a",Object(a.a)({parentName:"p"},{href:"https://github.com/onepanelio/templates/tree/master/workflows/hyperparameter-tuning/mnist/main.py"}),"MNIST example code")," to support hyperparameter tuning. The ",Object(r.b)("inlineCode",{parentName:"p"},"...")," indicate code that was removed for brevity."),Object(r.b)("pre",{parentName:"li"},Object(r.b)("code",Object(a.a)({parentName:"pre"},{className:"language-python",metastring:"{1,4-7,25,32,49-50}","{1,4-7,25,32,49-50}":!0}),"import nni\n\n# Callback class for reporting intermediate accuracy metrics.\nclass ReportIntermediates(Callback):\n    def on_epoch_end(self, epoch, logs=None):\n        \"\"\"Reports intermediate accuracy to NNI framework\"\"\"\n        nni.report_intermediate_result(logs['val_accuracy'])\n\ndef main(args, params):\n    ...\n\n    model = tf.keras.Sequential([\n        ...\n    ])\n    model.compile(...)\n\n    ...\n\n    model.fit(\n        x_train,\n        y_train,\n        batch_size=params['batch_size'],\n        epochs=params['epochs'],\n        # Add callback class for intermediate accuracy reporting\n        callbacks=[ReportIntermediates(), tensorboard],\n        validation_data=(x_test, y_test)\n    )\n\n    ...\n    \n    # send final accuracy to NNI tuner and web UI\n    nni.report_final_result(accuracy)\n    \n    ...\n\nif __name__ == '__main__':\n    ...\n\n    params = {\n        'dropout_rate': 0.5,\n        'conv_size': 5,\n        'hidden_size': 1024,\n        'batch_size': 32,\n        'learning_rate': 1e-4,\n        'epochs': 10,\n    }\n\n    # fetch hyper-parameters from NNI tuner\n    tuned_params = nni.get_next_parameter()\n    params.update(tuned_params)\n\n    _logger.info('Hyperparameters: %s', params)\n    main(parser.parse_args(), params)\n"))),Object(r.b)("li",{parentName:"ol"},Object(r.b)("p",{parentName:"li"},"Go to ",Object(r.b)("strong",{parentName:"p"},"Workflows")," > ",Object(r.b)("strong",{parentName:"p"},"Workflow Templates")," > ",Object(r.b)("strong",{parentName:"p"},"Hyperparameter Tuning Example")," and click ",Object(r.b)("strong",{parentName:"p"},"Clone"),".")),Object(r.b)("li",{parentName:"ol"},Object(r.b)("p",{parentName:"li"},"Update the cloned Workflow Template to use your repository and update the paths in ",Object(r.b)("inlineCode",{parentName:"p"},"/mnt/src")," to match your repository's directory structure. The ",Object(r.b)("inlineCode",{parentName:"p"},"...")," indicate sections that were removed for brevity."),Object(r.b)("pre",{parentName:"li"},Object(r.b)("code",Object(a.a)({parentName:"pre"},{className:"language-yaml",metastring:"{6,26,31,40}","{6,26,31,40}":!0}),"entrypoint: main\narguments:\n    parameters:\n    - name: source\n      # Path to your training/model architecture code repository\n      value: https://github.com/onepanelio/templates\n...\ntemplates:\n- name: main\n    dag:\n        tasks:\n        - name: hyperparameter-tuning\n          template: hyperparameter-tuning\n...\n- name: hyperparameter-tuning\n  inputs:\n    artifacts:\n    - name: src\n      # Clone the above repository into `/mnt/data/src` - see https://docs.onepanel.ai/docs/reference/workflows/artifacts#git for private repositories\n      git:\n        repo: '{{workflow.parameters.source}}'\n        revision: '{{workflow.parameters.revision}}'\n      path: /mnt/data/src\n    - name: config\n      # Path to where your tuner configuration (config.yaml) will be written - same directory as your training code\n      path: /mnt/data/src/<path-to-training-code-directory>/config.yaml\n      raw:\n        data: '{{workflow.parameters.config}}'\n    - name: search-space\n      # Path to where your hyperparameter search space (search_space.json) will be written - same directory as your training code\n      path: /mnt/data/src/<path-to-training-code-directory>/search_space.json\n      raw:\n        data: '{{workflow.parameters.search-space}}'\n...\n  container:\n    image: onepanel/dl:0.17.0\n    args:\n        - --config\n        # Path to config.yaml file that is written above\n        - /mnt/data/src/<path-to-training-code-directory>/config.yaml\n...\n"))),Object(r.b)("li",{parentName:"ol"},Object(r.b)("p",{parentName:"li"},"Update the Workflow Template title and click ",Object(r.b)("strong",{parentName:"p"},"Save"),"."))),Object(r.b)("h2",{id:"understanding-the-configurations"},"Understanding the configurations"),Object(r.b)("p",null,"When you attempt to execute the hyperparameter tuning Workflow Template, you'll notice two parameters, ",Object(r.b)("inlineCode",{parentName:"p"},"Configuration")," and ",Object(r.b)("inlineCode",{parentName:"p"},"Search space configuration"),". The former is the tuner configuration and the latter is the configuration for your hyperparameters and their corresponding search spaces."),Object(r.b)("p",null,"Here is a description of each of the fields in the ",Object(r.b)("inlineCode",{parentName:"p"},"Configuration")," parameter:"),Object(r.b)("pre",null,Object(r.b)("code",Object(a.a)({parentName:"pre"},{className:"language-yaml"}),"authorName: Onepanel, Inc.          # Name of the author\nexperimentName: MNIST TF v2.x       # Name of experiment\ntrialConcurrency: 1                 # Concurrency of trials, note that if on GPU, this should match gpuNum\nmaxExecDuration: 1h                 # Maximum duration of each trial\nmaxTrialNum: 10                     # Maximum number of trials\ntrainingServicePlatform: local      # This should always be set to `local`\nsearchSpacePath: search_space.json  # Path to search_space.json file - you don't have to change this if you follow the steps above\nuseAnnotation: false\ntuner:\n    # gpuIndices: '0'               # Uncomment and update to the GPU indices to assign this tuner\n    builtinTunerName: TPE           # Choices: TPE, Random, Anneal, Evolution, BatchTuner, MetisTuner, GPTuner\n    classArgs:\n        optimize_mode: maximize     # Choices: maximize, minimize\ntrial:\n    command: python main.py --output /mnt/output    # Command to execute your training code\n    codeDir: .\n    # gpuNum: 1                     # Uncomment and update to number of GPUs\n")),Object(r.b)("div",{className:"admonition admonition-important alert alert--info"},Object(r.b)("div",Object(a.a)({parentName:"div"},{className:"admonition-heading"}),Object(r.b)("h5",{parentName:"div"},Object(r.b)("span",Object(a.a)({parentName:"h5"},{className:"admonition-icon"}),Object(r.b)("svg",Object(a.a)({parentName:"span"},{xmlns:"http://www.w3.org/2000/svg",width:"14",height:"16",viewBox:"0 0 14 16"}),Object(r.b)("path",Object(a.a)({parentName:"svg"},{fillRule:"evenodd",d:"M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"})))),"important")),Object(r.b)("div",Object(a.a)({parentName:"div"},{className:"admonition-content"}),Object(r.b)("p",{parentName:"div"},"See ",Object(r.b)("a",Object(a.a)({parentName:"p"},{href:"https://nni.readthedocs.io/en/stable/Tutorial/ExperimentConfig.html"}),"NNI's Experiment Config Reference")," for more information and list of all available fields."))),Object(r.b)("p",null,Object(r.b)("inlineCode",{parentName:"p"},"Search space configuration")," content is in JSON format and it depends on the hyperparameters you intend to use in your training code. Example from the MNIST code above is as follows:"),Object(r.b)("pre",null,Object(r.b)("code",Object(a.a)({parentName:"pre"},{className:"language-json"}),'{\n    "dropout_rate": { "_type": "uniform", "_value": [0.5, 0.9] },\n    "conv_size": { "_type": "choice", "_value": [2, 3, 5, 7] },\n    "hidden_size": { "_type": "choice", "_value": [124, 512, 1024] },\n    "batch_size": { "_type": "choice", "_value": [16, 32] },\n    "learning_rate": { "_type": "choice", "_value": [0.0001, 0.001, 0.01, 0.1] },\n    "epochs": { "_type": "choice", "_value": [10] }\n}\n')),Object(r.b)("h2",{id:"executing-your-workflow"},"Executing your Workflow"),Object(r.b)("p",null,"Now that you have set up your hyperparameter tuning Workflow Template and have a good understanding of the various configurations, you can execute the Workflow via Onepanel ",Object(r.b)("a",Object(a.a)({parentName:"p"},{href:"/docs/reference/workflows/execute"}),"Web UI")," or ",Object(r.b)("a",Object(a.a)({parentName:"p"},{href:"https://github.com/onepanelio/python-sdk/blob/master/examples/execute-workflow.ipynb"}),"Python SDK"),". "),Object(r.b)("p",null,"Once the Workflow is running, you can see your training progress in ",Object(r.b)("strong",{parentName:"p"},"TensorBoard")," and ",Object(r.b)("strong",{parentName:"p"},"NNI Web UI")," right from your Workflow Task by clicking on the ",Object(r.b)("strong",{parentName:"p"},"hyperparameter-tuning")," Task, then clicking ",Object(r.b)("strong",{parentName:"p"},"Outputs"),"."),Object(r.b)("p",null,Object(r.b)("img",{src:n(246).default})),Object(r.b)("p",null,"Clicking ",Object(r.b)("strong",{parentName:"p"},"Open NNI Web UI")," will display the following screen in a new tab:"),Object(r.b)("p",null,Object(r.b)("img",{src:n(247).default})),Object(r.b)("p",null,"You can also view the corresponding TensorBoard by clicking ",Object(r.b)("strong",{parentName:"p"},"Open TensorBoard"),":"),Object(r.b)("p",null,Object(r.b)("img",{src:n(248).default})),Object(r.b)("h2",{id:"persisting-metrics-and-saving-best-model-and-parameters"},"Persisting metrics and saving best model and parameters"),Object(r.b)("p",null,"Although optional, you should persist the best metrics to your Workflow and save the best model and parameters to your object storage."),Object(r.b)("p",null,"Refer to the ",Object(r.b)("a",Object(a.a)({parentName:"p"},{href:"https://github.com/onepanelio/templates/tree/master/workflows/hyperparameter-tuning/mnist/main.py"}),"MNIST example code")," for an example of how to do this."),Object(r.b)("p",null,Object(r.b)("img",{src:n(249).default})))}s.isMDXComponent=!0}}]);