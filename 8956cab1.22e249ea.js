(window.webpackJsonp=window.webpackJsonp||[]).push([[34],{123:function(e,t,a){"use strict";a.d(t,"a",(function(){return p})),a.d(t,"b",(function(){return u}));var n=a(0),o=a.n(n);function i(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function c(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function r(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?c(Object(a),!0).forEach((function(t){i(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):c(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function s(e,t){if(null==e)return{};var a,n,o=function(e,t){if(null==e)return{};var a,n,o={},i=Object.keys(e);for(n=0;n<i.length;n++)a=i[n],t.indexOf(a)>=0||(o[a]=e[a]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(n=0;n<i.length;n++)a=i[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(o[a]=e[a])}return o}var l=o.a.createContext({}),b=function(e){var t=o.a.useContext(l),a=t;return e&&(a="function"==typeof e?e(t):r(r({},t),e)),a},p=function(e){var t=b(e.components);return o.a.createElement(l.Provider,{value:t},e.children)},m={inlineCode:"code",wrapper:function(e){var t=e.children;return o.a.createElement(o.a.Fragment,{},t)}},d=o.a.forwardRef((function(e,t){var a=e.components,n=e.mdxType,i=e.originalType,c=e.parentName,l=s(e,["components","mdxType","originalType","parentName"]),p=b(a),d=n,u=p["".concat(c,".").concat(d)]||p[d]||m[d]||i;return a?o.a.createElement(u,r(r({ref:t},l),{},{components:a})):o.a.createElement(u,r({ref:t},l))}));function u(e,t){var a=arguments,n=t&&t.mdxType;if("string"==typeof e||n){var i=a.length,c=new Array(i);c[0]=d;var r={};for(var s in t)hasOwnProperty.call(t,s)&&(r[s]=t[s]);r.originalType=e,r.mdxType="string"==typeof e?e:n,c[1]=r;for(var l=2;l<i;l++)c[l]=a[l];return o.a.createElement.apply(null,c)}return o.a.createElement.apply(null,a)}d.displayName="MDXCreateElement"},132:function(e,t,a){"use strict";a.r(t),t.default=a.p+"assets/images/cvat_open-f720c7c0bf600fa4cefeb1de339d730d.png"},135:function(e,t,a){"use strict";a.r(t),t.default=a.p+"assets/images/create_workspaces_button_in_workspaces_page-046390af8c3ed7dad84879f45a461165.png"},136:function(e,t,a){"use strict";a.r(t),t.default=a.p+"assets/images/tf-object-detection-b6a97ad0987f3362c789cfb36af1ebce.png"},138:function(e,t,a){"use strict";a.r(t),t.default=a.p+"assets/images/cvat_select_workflow_execution-ec9d8925cf9110729a481ea6088aa571.png"},139:function(e,t,a){"use strict";a.r(t),t.default=a.p+"assets/images/execution_url-d1c171f8a2d8e9af476838254702195d.png"},150:function(e,t,a){"use strict";a.r(t),t.default=a.p+"assets/images/quickstart-115738-445c393948e67e6ec4bc5b61082f7016.png"},151:function(e,t,a){"use strict";a.r(t),t.default=a.p+"assets/images/quickstart-133251-1338ebabe71eced17da32a7924187ff1.png"},152:function(e,t,a){"use strict";a.r(t),t.default=a.p+"assets/images/quickstart-171037-b64dac540bb33314348a64f61b5da01f.png"},153:function(e,t,a){"use strict";a.r(t),t.default=a.p+"assets/images/quickstart-173734-a730cfefda50e9301ae61a778b37a082.png"},154:function(e,t,a){"use strict";a.r(t),t.default=a.p+"assets/images/quickstart-173841-24b22c32f4c5b6fe151c17b51a5e70ce.png"},155:function(e,t,a){"use strict";a.r(t),t.default=a.p+"assets/images/quickstart-180004-b442bf62ee0ed96a5830563117f673a3.png"},156:function(e,t,a){"use strict";a.r(t),t.default=a.p+"assets/images/upload_model-558b35d2047ea4455ebf35a1e4add752.PNG"},157:function(e,t,a){"use strict";a.r(t),t.default=a.p+"assets/images/class_mapping-6b1522e59588573a2f253fc3d5bd115d.png"},158:function(e,t,a){"use strict";a.r(t),t.default=a.p+"assets/images/cvat_automatic_annotation_running-fd66040849fcf0e0c733dbe7cf580d45.png"},159:function(e,t,a){"use strict";a.r(t),t.default=a.p+"assets/images/cvat_inference_output-5edbe6b6eaf80718eb9b2fc1a767b0d0.png"},244:function(e,t,a){"use strict";a.r(t),t.default=a.p+"assets/images/cvat_draw_box-a5e348490b2f1dec38c09343aa063097.png"},245:function(e,t,a){"use strict";a.r(t),t.default=a.p+"assets/images/cvat_draw_polygon-2f7d783f3201cd8a7c8a9e37b9b985a9.png"},94:function(e,t,a){"use strict";a.r(t),a.d(t,"frontMatter",(function(){return i})),a.d(t,"metadata",(function(){return c})),a.d(t,"rightToc",(function(){return r})),a.d(t,"default",(function(){return l}));var n=a(2),o=(a(0),a(123));const i={title:"Getting started with image and video annotation in CVAT",sidebar_label:"Getting started with image and video annotation",description:"Onepanel - vision AI automatic annotation"},c={unversionedId:"getting-started/use-cases/computervision/annotation/cvat/cvat_quick_guide",id:"getting-started/use-cases/computervision/annotation/cvat/cvat_quick_guide",isDocsHomePage:!1,title:"Getting started with image and video annotation in CVAT",description:"Onepanel - vision AI automatic annotation",source:"@site/docs/getting-started/use-cases/computervision/annotation/cvat/cvat_quick_guide.md",slug:"/getting-started/use-cases/computervision/annotation/cvat/cvat_quick_guide",permalink:"/docs/getting-started/use-cases/computervision/annotation/cvat/cvat_quick_guide",editUrl:"https://github.com/onepanelio/core-docs/tree/master/docs/getting-started/use-cases/computervision/annotation/cvat/cvat_quick_guide.md",version:"current",sidebar_label:"Getting started with image and video annotation",sidebar:"reference",previous:{title:"Creating a Workflow Template",permalink:"/docs/reference/workflows/create"},next:{title:"Training built-in annotation models on CVAT",permalink:"/docs/getting-started/use-cases/computervision/annotation/cvat/cvat_annotation_model"}},r=[{value:"1. Setting up CVAT",id:"1-setting-up-cvat",children:[]},{value:"2. Annotating frames in CVAT",id:"2-annotating-frames-in-cvat",children:[]},{value:"3. Training new annotation model from CVAT",id:"3-training-new-annotation-model-from-cvat",children:[]},{value:"4. Using deep learning models for pre-annotation",id:"4-using-deep-learning-models-for-pre-annotation",children:[]}],s={rightToc:r};function l({components:e,...t}){return Object(o.b)("wrapper",Object(n.a)({},s,t,{components:e,mdxType:"MDXLayout"}),Object(o.b)("p",null,"For this quick start, we'll be using OpenCV's ",Object(o.b)("a",Object(n.a)({parentName:"p"},{href:"https://github.com/opencv/cvat"}),"Computer Vision Annotation Tool (CVAT)"),". You will be able to use an existing model to pre-annotate your images or videos and then continuously train and improve your model on new data."),Object(o.b)("p",null,"For this quick start, we'll setup CVAT on Onepanel, annotate some images, train a model on this images, and use this newly trained model for pre-annotation."),Object(o.b)("h2",{id:"1-setting-up-cvat"},"1. Setting up CVAT"),Object(o.b)("p",null,"Onepanel is fully integrated with ",Object(o.b)("a",Object(n.a)({parentName:"p"},{href:"https://github.com/opencv/cvat"}),"Computer Vision Annotation Tool (CVAT)"),", allowing you to annotate images and videos and then train models on the annotated data with a few clicks. You can then use these newly trained models to automatically pre-annotate additional data, iteratively improving your object detection or semantic segmentation models."),Object(o.b)("div",{className:"admonition admonition-tip alert alert--success"},Object(o.b)("div",Object(n.a)({parentName:"div"},{className:"admonition-heading"}),Object(o.b)("h5",{parentName:"div"},Object(o.b)("span",Object(n.a)({parentName:"h5"},{className:"admonition-icon"}),Object(o.b)("svg",Object(n.a)({parentName:"span"},{xmlns:"http://www.w3.org/2000/svg",width:"12",height:"16",viewBox:"0 0 12 16"}),Object(o.b)("path",Object(n.a)({parentName:"svg"},{fillRule:"evenodd",d:"M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"})))),"tip")),Object(o.b)("div",Object(n.a)({parentName:"div"},{className:"admonition-content"}),Object(o.b)("p",{parentName:"div"},"You can also bring your own labeling tool as a reproducible template in Onepanel. See our ",Object(o.b)("a",Object(n.a)({parentName:"p"},{href:"/docs/reference/workspaces/templates"}),"Workspace templates documentation")," for more information."))),Object(o.b)("ol",null,Object(o.b)("li",{parentName:"ol"},Object(o.b)("p",{parentName:"li"},"Go to ",Object(o.b)("strong",{parentName:"p"},"Workspaces")," and click ",Object(o.b)("strong",{parentName:"p"},"Create Workspace"),"."),Object(o.b)("p",{parentName:"li"},Object(o.b)("img",{alt:"Create Workspace",src:a(135).default}))),Object(o.b)("li",{parentName:"ol"},Object(o.b)("p",{parentName:"li"},"Select the CVAT template and enter a name for your Workspace."),Object(o.b)("p",{parentName:"li"},Object(o.b)("img",{src:a(150).default}))),Object(o.b)("li",{parentName:"ol"},Object(o.b)("p",{parentName:"li"},"Select a node pool that Onepanel will use to provision a machine for running CVAT. CVAT requires at least 16GB of RAM."),Object(o.b)("p",{parentName:"li"},Object(o.b)("img",{src:a(151).default})),Object(o.b)("div",Object(n.a)({parentName:"li"},{className:"admonition admonition-note alert alert--secondary"}),Object(o.b)("div",Object(n.a)({parentName:"div"},{className:"admonition-heading"}),Object(o.b)("h5",{parentName:"div"},Object(o.b)("span",Object(n.a)({parentName:"h5"},{className:"admonition-icon"}),Object(o.b)("svg",Object(n.a)({parentName:"span"},{xmlns:"http://www.w3.org/2000/svg",width:"14",height:"16",viewBox:"0 0 14 16"}),Object(o.b)("path",Object(n.a)({parentName:"svg"},{fillRule:"evenodd",d:"M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"})))),"note")),Object(o.b)("div",Object(n.a)({parentName:"div"},{className:"admonition-content"}),Object(o.b)("p",{parentName:"div"},"Some providers have limits on how many volumes you can attach to a node. The default CVAT template in Onepanel requires 3 volumes, so make sure to pick a machine that can support at least that many volumes."))),Object(o.b)("div",Object(n.a)({parentName:"li"},{className:"admonition admonition-tip alert alert--success"}),Object(o.b)("div",Object(n.a)({parentName:"div"},{className:"admonition-heading"}),Object(o.b)("h5",{parentName:"div"},Object(o.b)("span",Object(n.a)({parentName:"h5"},{className:"admonition-icon"}),Object(o.b)("svg",Object(n.a)({parentName:"span"},{xmlns:"http://www.w3.org/2000/svg",width:"12",height:"16",viewBox:"0 0 12 16"}),Object(o.b)("path",Object(n.a)({parentName:"svg"},{fillRule:"evenodd",d:"M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"})))),"tip")),Object(o.b)("div",Object(n.a)({parentName:"div"},{className:"admonition-content"}),Object(o.b)("p",{parentName:"div"},"You can switch to a different node pool (for example one that supports GPUs) in a running Workspace at any time by clicking the Onepanel icon in the bottom right corner of your Workspace.")))),Object(o.b)("li",{parentName:"ol"},Object(o.b)("p",{parentName:"li"},"Next, add the directory you want Onepanel to pull raw input data and store training output (pickled models, classes, etc.). This directory should be in the default object storage you configured when you launched Onepanel and in a directory that matches your current namespace."),Object(o.b)("p",{parentName:"li"},Object(o.b)("img",{src:a(152).default}))),Object(o.b)("li",{parentName:"ol"},Object(o.b)("p",{parentName:"li"},"Click ",Object(o.b)("strong",{parentName:"p"},"Create and Run")," to launch your CVAT Workspace.")),Object(o.b)("li",{parentName:"ol"},Object(o.b)("p",{parentName:"li"},"Once CVAT is running, click ",Object(o.b)("strong",{parentName:"p"},"View"),"."),Object(o.b)("p",{parentName:"li"},Object(o.b)("img",{src:a(153).default}))),Object(o.b)("li",{parentName:"ol"},Object(o.b)("p",{parentName:"li"},"In CVAT, click ",Object(o.b)("strong",{parentName:"p"},"Create new task"),"."),Object(o.b)("p",{parentName:"li"},Object(o.b)("img",{src:a(154).default}))),Object(o.b)("li",{parentName:"ol"},Object(o.b)("p",{parentName:"li"},"Enter a name for your task and then under ",Object(o.b)("strong",{parentName:"p"},"Constructor"),", add your labels. See ",Object(o.b)("a",Object(n.a)({parentName:"p"},{href:"https://github.com/opencv/cvat/blob/develop/cvat/apps/documentation/user_guide.md#creating-an-annotation-task"}),"CVAT's user guide")," for additional information on more advanced label configuration.")),Object(o.b)("li",{parentName:"ol"},Object(o.b)("p",{parentName:"li"},'Under "Select files", click ',Object(o.b)("strong",{parentName:"p"},"Connected file share"),". Files from your object storage location above should have already synced here. Pick the ones you want to annotate."),Object(o.b)("p",{parentName:"li"},Object(o.b)("img",{src:a(155).default})),Object(o.b)("div",Object(n.a)({parentName:"li"},{className:"admonition admonition-important alert alert--info"}),Object(o.b)("div",Object(n.a)({parentName:"div"},{className:"admonition-heading"}),Object(o.b)("h5",{parentName:"div"},Object(o.b)("span",Object(n.a)({parentName:"h5"},{className:"admonition-icon"}),Object(o.b)("svg",Object(n.a)({parentName:"span"},{xmlns:"http://www.w3.org/2000/svg",width:"14",height:"16",viewBox:"0 0 14 16"}),Object(o.b)("path",Object(n.a)({parentName:"svg"},{fillRule:"evenodd",d:"M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"})))),"important")),Object(o.b)("div",Object(n.a)({parentName:"div"},{className:"admonition-content"}),Object(o.b)("p",{parentName:"div"},"Onepanel's FileSyncer automatically syncs files from your object storage location to this CVAT instance (",Object(o.b)("inlineCode",{parentName:"p"},"/mnt/share"),") every 5 minutes. You should not change the directory on local machine since CVAT reads data from that directory. However, you can specify directory on your cloud storage (i.e S3). By default, this directory on cloud storage is ",Object(o.b)("inlineCode",{parentName:"p"},"workflow-data"),". We recommend you don't change this directory. But if required, you can change this directory by modifying default directory name while creating CVAT workspace."),Object(o.b)("p",{parentName:"div"},"You can put raw input files inside ",Object(o.b)("inlineCode",{parentName:"p"},"workflow-data/<sample-input-folder>")," as Workflow outputs will be stored in ",Object(o.b)("inlineCode",{parentName:"p"},"workflow-data/output"),".")))),Object(o.b)("li",{parentName:"ol"},Object(o.b)("p",{parentName:"li"},"Click ",Object(o.b)("strong",{parentName:"p"},"Submit")," and then click the ",Object(o.b)("strong",{parentName:"p"},"Tasks")," menu item to go to the tasks list.")),Object(o.b)("li",{parentName:"ol"},Object(o.b)("p",{parentName:"li"},"Click ",Object(o.b)("strong",{parentName:"p"},"Open")," to open task details."),Object(o.b)("p",{parentName:"li"},Object(o.b)("img",{src:a(132).default}))),Object(o.b)("li",{parentName:"ol"},Object(o.b)("p",{parentName:"li"},"Click ",Object(o.b)("strong",{parentName:"p"},"Job #1")," to go into CVAT to start annotating your data. See ",Object(o.b)("a",Object(n.a)({parentName:"p"},{href:"https://github.com/opencv/cvat/blob/develop/cvat/apps/documentation/user_guide.md#interface-of-the-annotation-tool"}),"CVAT's user guide")," for more information on the annotation tool interface."))),Object(o.b)("h2",{id:"2-annotating-frames-in-cvat"},"2. Annotating frames in CVAT"),Object(o.b)("p",null,"Once you have created a new task, you can start annotating your data. CVAT supports points, box, polylines, polygons for annotation. "),Object(o.b)("ol",null,Object(o.b)("li",{parentName:"ol"},Object(o.b)("p",{parentName:"li"},"Click ",Object(o.b)("strong",{parentName:"p"},"Open")," to open task details."),Object(o.b)("p",{parentName:"li"},Object(o.b)("img",{src:a(132).default}))),Object(o.b)("li",{parentName:"ol"},Object(o.b)("p",{parentName:"li"},"Click ",Object(o.b)("strong",{parentName:"p"},"Job #1")," to go into CVAT to start annotating your data. See ",Object(o.b)("a",Object(n.a)({parentName:"p"},{href:"https://github.com/opencv/cvat/blob/develop/cvat/apps/documentation/user_guide.md#interface-of-the-annotation-tool"}),"CVAT's user guide")," for more information on the annotation tool interface."),Object(o.b)("ul",{parentName:"li"},Object(o.b)("li",{parentName:"ul"},Object(o.b)("p",{parentName:"li"},Object(o.b)("strong",{parentName:"p"},"Bounding box"),":\nSelect Box from the left sidebar and press N to start annotating once done, press N to finish annotation. Sometimes N will draw ",Object(o.b)("inlineCode",{parentName:"p"},"rectangle shape")," and sometimes it will draw ",Object(o.b)("inlineCode",{parentName:"p"},"rectangle track"),". In order to ensure you have the right one, draw one box by manually selecting Shape or Track from the UI. Once you manually select type of box from the UI, it will draw what you selected for the box everytime you press N.\n",Object(o.b)("img",{alt:"Annotation",src:a(244).default}))),Object(o.b)("li",{parentName:"ul"},Object(o.b)("p",{parentName:"li"},Object(o.b)("strong",{parentName:"p"},"Polygons"),":\nSimilarly, select polygons or polylines and follow same procedure for annotation.\n",Object(o.b)("img",{alt:"Select annotation",src:a(245).default}))))),Object(o.b)("li",{parentName:"ol"},Object(o.b)("p",{parentName:"li"},"Press ",Object(o.b)("inlineCode",{parentName:"p"},"ctrl")," + ",Object(o.b)("inlineCode",{parentName:"p"},"s")," to save your task."),Object(o.b)("div",Object(n.a)({parentName:"li"},{className:"admonition admonition-tip alert alert--success"}),Object(o.b)("div",Object(n.a)({parentName:"div"},{className:"admonition-heading"}),Object(o.b)("h5",{parentName:"div"},Object(o.b)("span",Object(n.a)({parentName:"h5"},{className:"admonition-icon"}),Object(o.b)("svg",Object(n.a)({parentName:"span"},{xmlns:"http://www.w3.org/2000/svg",width:"12",height:"16",viewBox:"0 0 12 16"}),Object(o.b)("path",Object(n.a)({parentName:"svg"},{fillRule:"evenodd",d:"M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"})))),"tip")),Object(o.b)("div",Object(n.a)({parentName:"div"},{className:"admonition-content"}),Object(o.b)("p",{parentName:"div"},"It is highly recommended that you dump your annotation periodically. In case of any failure, this can be used to recover the tasks."))),Object(o.b)("div",Object(n.a)({parentName:"li"},{className:"admonition admonition-note alert alert--secondary"}),Object(o.b)("div",Object(n.a)({parentName:"div"},{className:"admonition-heading"}),Object(o.b)("h5",{parentName:"div"},Object(o.b)("span",Object(n.a)({parentName:"h5"},{className:"admonition-icon"}),Object(o.b)("svg",Object(n.a)({parentName:"span"},{xmlns:"http://www.w3.org/2000/svg",width:"14",height:"16",viewBox:"0 0 14 16"}),Object(o.b)("path",Object(n.a)({parentName:"svg"},{fillRule:"evenodd",d:"M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"})))),"note")),Object(o.b)("div",Object(n.a)({parentName:"div"},{className:"admonition-content"}),Object(o.b)("p",{parentName:"div"},"Note that you can use pre-trained models for pre-annotation of your frames. This will drastically reduce time it takes for annotation. For more information on pre-annotation, see section 4."))))),Object(o.b)("h2",{id:"3-training-new-annotation-model-from-cvat"},"3. Training new annotation model from CVAT"),Object(o.b)("p",null,"Onepanel also allows you to train or further finetune your model for pre-annotation in CVAT or any other use cases. Once you are done with your annotation or adjustment to pre-annotation, you can train a new model on it. "),Object(o.b)("ol",null,Object(o.b)("li",{parentName:"ol"},Object(o.b)("p",{parentName:"li"},"Click on ",Object(o.b)("strong",{parentName:"p"},"Actions")," for a task you want to train a model on. Then, click on ",Object(o.b)("strong",{parentName:"p"},"Execute training Workflow"),"."),Object(o.b)("p",{parentName:"li"},Object(o.b)("img",{alt:"Select training workflow",src:a(138).default}))),Object(o.b)("li",{parentName:"ol"},Object(o.b)("p",{parentName:"li"},"Select Workflow template (i.e model to train). By default, you can use TensorFlow Object Detection for object detection or MaskRCNN for semantic segmentation. Below image shows a case for Tensorflow Object Detection."),Object(o.b)("p",{parentName:"li"},Object(o.b)("img",{alt:"Train a model from CVAT",src:a(136).default}))),Object(o.b)("li",{parentName:"ol"},Object(o.b)("p",{parentName:"li"},"Update hyper-parameters and settings as per your requirements. Most of the parameters visible above are related to the model (MaskRCNN) and system (i.e machine). For this guide, you can change ",Object(o.b)("inlineCode",{parentName:"p"},"num-steps")," from default 10000 to 1000. You can also select the checkpoint path from previously trained model. You can leave it empty if you don't have an appropriate, previously trained model.")),Object(o.b)("li",{parentName:"ol"},Object(o.b)("p",{parentName:"li"},"Click ",Object(o.b)("strong",{parentName:"p"},"Submit"),". This will execute the Onepanel Workflow for selected model. You can see Workflow logs by going to Workflow execution page. You can find the URL for the same in the notification card."),Object(o.b)("p",{parentName:"li"},Object(o.b)("img",{alt:"Workflow URL",src:a(139).default})),Object(o.b)("div",Object(n.a)({parentName:"li"},{className:"admonition admonition-tip alert alert--success"}),Object(o.b)("div",Object(n.a)({parentName:"div"},{className:"admonition-heading"}),Object(o.b)("h5",{parentName:"div"},Object(o.b)("span",Object(n.a)({parentName:"h5"},{className:"admonition-icon"}),Object(o.b)("svg",Object(n.a)({parentName:"span"},{xmlns:"http://www.w3.org/2000/svg",width:"12",height:"16",viewBox:"0 0 12 16"}),Object(o.b)("path",Object(n.a)({parentName:"svg"},{fillRule:"evenodd",d:"M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"})))),"tip")),Object(o.b)("div",Object(n.a)({parentName:"div"},{className:"admonition-content"}),Object(o.b)("p",{parentName:"div"},"Note that you can easily add your own models as well. See ",Object(o.b)("a",Object(n.a)({parentName:"p"},{href:"/docs/getting-started/use-cases/computervision/annotation/cvat/adding_custom_model"}),"adding custom models")," for more information on adding custom models."),Object(o.b)("p",{parentName:"div"},"You can also use this trained model to run pre-annotation in CVAT. See ",Object(o.b)("a",Object(n.a)({parentName:"p"},{href:"/docs/getting-started/use-cases/computervision/annotation/cvat/cvat_automatic_annotation"}),"automatic annotation")," for more information on pre-annotation."))))),Object(o.b)("h2",{id:"4-using-deep-learning-models-for-pre-annotation"},"4. Using deep learning models for pre-annotation"),Object(o.b)("p",null,"Onepanel\u2019s CVAT supports a feature to pre-annotate images for common objects. You can add your custom models to pre-annotation other objects as well. In order to use any pre-annotation feature, you first need to upload the model. By default, we provide Faster RCNN for object detection and Mask RCNN for semantic segmentation. "),Object(o.b)("ol",null,Object(o.b)("li",{parentName:"ol"},Object(o.b)("p",{parentName:"li"},"To upload a model, click on ",Object(o.b)("strong",{parentName:"p"},"Models"),", and then click on ",Object(o.b)("strong",{parentName:"p"},"Create new model"),". ")),Object(o.b)("li",{parentName:"ol"},Object(o.b)("p",{parentName:"li"},"Click on select files and upload your model (",Object(o.b)("inlineCode",{parentName:"p"},".pb")," and ",Object(o.b)("inlineCode",{parentName:"p"},".csv")," for Tensorflow Object Detectio and ",Object(o.b)("inlineCode",{parentName:"p"},".h5")," and ",Object(o.b)("inlineCode",{parentName:"p"},".csv")," for MaskRCNN). Hit submit to upload the model."),Object(o.b)("p",{parentName:"li"},Object(o.b)("img",{alt:"Model Manager",src:a(156).default}))),Object(o.b)("li",{parentName:"ol"},Object(o.b)("p",{parentName:"li"},"Click on ",Object(o.b)("strong",{parentName:"p"},"Automatic annotation")," under Actions menu. Then, you will be asked to select the model you want to use for pre-annotation. You can also control the class mapping from your task\u2019s classes to model\u2019s classes."),Object(o.b)("p",{parentName:"li"},Object(o.b)("img",{alt:"Class mapping",src:a(157).default}))),Object(o.b)("li",{parentName:"ol"},Object(o.b)("p",{parentName:"li"},"Click on ",Object(o.b)("strong",{parentName:"p"},"Submit")," to start pre-annotation. Once it's done, you can click on ",Object(o.b)("strong",{parentName:"p"},"Open")," to access the annotation."),Object(o.b)("p",{parentName:"li"},Object(o.b)("img",{alt:"Automatic Annotation Running",src:a(158).default})),Object(o.b)("p",{parentName:"li"},Object(o.b)("img",{alt:"Inference Output",src:a(159).default})))),Object(o.b)("p",null,"If you need help or have questions regarding CVAT, feel free to reach out in ",Object(o.b)("a",Object(n.a)({parentName:"p"},{href:"https://join.slack.com/t/onepanel-ce/shared_invite/zt-eyjnwec0-nLaHhjif9Y~gA05KuX6AUg"}),"Slack")," or  ",Object(o.b)("a",Object(n.a)({parentName:"p"},{href:"https://github.com/onepanelio/core/discussions"}),"GitHub discussions"),"."))}l.isMDXComponent=!0}}]);